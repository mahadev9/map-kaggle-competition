{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42320a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "TRAIN_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"train.csv\")\n",
    "TEST_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Misconception = train_df.Misconception.fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faef9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"predict\"] = train_df.Category + \":\" + train_df.Misconception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_mc_answer_correct\"] = train_df.Category.str.contains(\"True\", case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_student_explanation_correct\"] = train_df.Category.str.contains(\"Correct\", case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_df[\"label\"] = le.fit_transform(train_df[\"predict\"])\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train_df.shape} with {n_classes} predict classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_input(row):\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\\n\\n\"\n",
    "        f\"Is the student's answer correct? {row['is_mc_answer_correct']}\\n\"\n",
    "        f\"Is the student's explanation correct? {row['is_student_explanation_correct']}\\n\"\n",
    "    )\n",
    "\n",
    "train_df[\"stringified_input\"] = train_df.apply(stringify_input, axis=1)\n",
    "\n",
    "train_df.stringified_input.values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4df31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_df, model_val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ded2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"stringified_input\", \"label\"]\n",
    "\n",
    "train_ds = Dataset.from_pandas(model_train_df[COLUMNS])\n",
    "val_ds = Dataset.from_pandas(model_val_df[COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "seq_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61960aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"stringified_input\"], truncation=True, padding=\"max_length\", max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_ds.set_format(type='torch', columns=columns)\n",
    "val_ds.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6991810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_map3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "    top3 = np.argsort(-probs, axis=1)[:, :3]  # Top 3 predictions\n",
    "    match = (top3 == labels[:, None])\n",
    "\n",
    "    # Compute MAP@3 manually\n",
    "    map3 = 0\n",
    "    for i in range(len(labels)):\n",
    "        if match[i, 0]:\n",
    "            map3 += 1.0\n",
    "        elif match[i, 1]:\n",
    "            map3 += 1.0 / 2\n",
    "        elif match[i, 2]:\n",
    "            map3 += 1.0 / 3\n",
    "    return {\"map@3\": map3 / len(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\", #no for no saving\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=16*2,\n",
    "    per_device_eval_batch_size=32*2,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    # use_mps_device=True,  # Use MPS for Apple Silicon\n",
    "    bf16=True, # TRAIN WITH BF16 IF LOCAL GPU IS NEWER GPU\n",
    "    # fp16=True, # INFER WITH FP16 BECAUSE KAGGLE IS T4 GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=seq_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_map3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.merge(\n",
    "    train_df[\n",
    "        [\n",
    "            \"QuestionText\",\n",
    "            \"MC_Answer\",\n",
    "            \"is_mc_answer_correct\",\n",
    "            \"is_student_explanation_correct\",\n",
    "        ]\n",
    "    ],\n",
    "    how=\"left\",\n",
    "    on=[\"QuestionText\", \"MC_Answer\"],\n",
    ")\n",
    "\n",
    "test_df[\"stringified_input\"] = test_df.apply(stringify_input, axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset.from_pandas(test_df[[\"stringified_input\"]])\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_ds)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91329248",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = np.argsort(-probs, axis=1)[:, :3]\n",
    "\n",
    "# Decode numeric class indices to original string labels\n",
    "flat_top3 = top3.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_top3)\n",
    "top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "# Join 3 labels per row with space\n",
    "joined_preds = [\" \".join(row) for row in top3_labels]\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test_df.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
