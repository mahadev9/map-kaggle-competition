{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a9878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import gc\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "if \"/kaggle\" in ROOT_PATH:\n",
    "    ROOT_PATH = \"/kaggle/input\"\n",
    "    sys.path.append(os.path.join(ROOT_PATH, \"map-utilities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdd51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel,\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    stringify_input,\n",
    "    get_model_name,\n",
    "    get_sequence_classifier,\n",
    "    get_tokenizer,\n",
    "    get_training_arguments,\n",
    "    get_trainer,\n",
    "    convert_latex_to_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_MODEL = \"microsoft/deberta-v3-large\"\n",
    "# BASE_MODEL = \"answerdotai/ModernBERT-large\"\n",
    "# BASE_MODEL = \"jhu-clsp/ettin-encoder-1b\"\n",
    "# BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "# BASE_MODEL = \"google/gemma-2-9b-it\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-1.7B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-8B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-14B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "# BASE_MODEL = \"Qwen/Qwen2.5-Coder-14B-Instruct\"\n",
    "# BASE_MODEL = \"deepseek-ai/deepseek-math-7b-instruct\"\n",
    "# BASE_MODEL = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\n",
    "# BASE_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "BASE_MODEL = \"Qwen/Qwen3-Embedding-4B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-Embedding-8B\"\n",
    "# BASE_MODEL = \"nvidia/AceMath-1.5B-Instruct\"\n",
    "# BASE_MODEL = \"nvidia/AceReason-Nemotron-1.1-7B\"\n",
    "# BASE_MODEL = \"nvidia/AceReason-Nemotron-14B\"\n",
    "# BASE_MODEL = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# BASE_MODEL = \"google/t5gemma-l-l-ul2-it\"\n",
    "# BASE_MODEL = \"google/t5gemma-2b-2b-ul2-it\"\n",
    "# BASE_MODEL = \"google/t5gemma-9b-2b-ul2-it\"\n",
    "# BASE_MODEL = \"google/gemma-3-1b-it\"\n",
    "# BASE_MODEL = \"google/gemma-3-12b-it\"\n",
    "\n",
    "N_FOLDS = 5\n",
    "TOP_K = 10\n",
    "SPLIT_RATIO = 0.2\n",
    "MAX_LEN = 256\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 16\n",
    "MODEL_NAME = get_model_name(\"/kaggle\" in ROOT_PATH, ROOT_PATH, BASE_MODEL)\n",
    "\n",
    "USE_LORA = True\n",
    "USE_QLORA = False\n",
    "BITS = 4\n",
    "USE_4BIT = BITS == 4\n",
    "USE_8BIT = BITS == 8\n",
    "\n",
    "TRAIN_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"train.csv\")\n",
    "TEST_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737e7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ec8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (36696, 7)\n",
      "Testing Shape: (3, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape:\", train_df.shape)\n",
    "print(\"Testing Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defda15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Misconception = train_df.Misconception.fillna(\"NA\")\n",
    "train_df[\"predict\"] = train_df.Category + \":\" + train_df.Misconception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9836c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2000262/1307861462.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df.is_mc_answer_correct = train_df.is_mc_answer_correct.fillna(False)\n",
      "/tmp/ipykernel_2000262/1307861462.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df.is_mc_answer_correct = test_df.is_mc_answer_correct.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "idx = train_df.Category.str.contains(\"True\", case=False)\n",
    "tmp = train_df.loc[idx].copy()\n",
    "tmp[\"c\"] = tmp.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "tmp = tmp.sort_values(\"c\", ascending=False)\n",
    "tmp = tmp.drop_duplicates([\"QuestionId\"])\n",
    "tmp = tmp[[\"QuestionId\", \"MC_Answer\"]]\n",
    "tmp[\"is_mc_answer_correct\"] = True\n",
    "\n",
    "train_df = train_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "train_df.is_mc_answer_correct = train_df.is_mc_answer_correct.fillna(False)\n",
    "\n",
    "test_df = test_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "test_df.is_mc_answer_correct = test_df.is_mc_answer_correct.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82e38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_student_explanation_correct\"] = train_df.Category.apply(\n",
    "    lambda x: 0 if \"Neither\" in x else (1 if \"Correct\" in x else 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f3a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/.venv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.1 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36696, 11) with 65 predict classes\n"
     ]
    }
   ],
   "source": [
    "# le = LabelEncoder()\n",
    "le = joblib.load(os.path.join(ROOT_PATH, \"label_encoder.joblib\"))\n",
    "\n",
    "train_df[\"label\"] = le.transform(train_df[\"predict\"])\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train_df.shape} with {n_classes} predict classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af5b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>MC_Answer</th>\n",
       "      <th>StudentExplanation</th>\n",
       "      <th>Category</th>\n",
       "      <th>Misconception</th>\n",
       "      <th>predict</th>\n",
       "      <th>is_mc_answer_correct</th>\n",
       "      <th>is_student_explanation_correct</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>0ne third is equal to tree nineth</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 3rd is half of 3 6th, so it is simplee to un...</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Neither:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 goes into everything and 3 goes into nine</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Neither:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 out of every 3 isn't coloured</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  QuestionId                                       QuestionText  \\\n",
       "0       0       31772  What fraction of the shape is not shaded? Give...   \n",
       "1       1       31772  What fraction of the shape is not shaded? Give...   \n",
       "2       2       31772  What fraction of the shape is not shaded? Give...   \n",
       "3       3       31772  What fraction of the shape is not shaded? Give...   \n",
       "4       4       31772  What fraction of the shape is not shaded? Give...   \n",
       "\n",
       "           MC_Answer                                 StudentExplanation  \\\n",
       "0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n",
       "1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n",
       "2  \\( \\frac{1}{3} \\)  1 3rd is half of 3 6th, so it is simplee to un...   \n",
       "3  \\( \\frac{1}{3} \\)        1 goes into everything and 3 goes into nine   \n",
       "4  \\( \\frac{1}{3} \\)                    1 out of every 3 isn't coloured   \n",
       "\n",
       "       Category Misconception          predict  is_mc_answer_correct  \\\n",
       "0  True_Correct            NA  True_Correct:NA                  True   \n",
       "1  True_Correct            NA  True_Correct:NA                  True   \n",
       "2  True_Neither            NA  True_Neither:NA                  True   \n",
       "3  True_Neither            NA  True_Neither:NA                  True   \n",
       "4  True_Correct            NA  True_Correct:NA                  True   \n",
       "\n",
       "   is_student_explanation_correct  label  \n",
       "0                               1     37  \n",
       "1                               1     37  \n",
       "2                               0     64  \n",
       "3                               0     64  \n",
       "4                               1     37  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93ee45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.]',\n",
       "       'Calculate ( (1)/(2) / 6 )',\n",
       "       'A box contains ( 120 ) counters. The counters are red or blue. ( (3)/(5) ) of the counters are red.\\nHow many red counters are there?',\n",
       "       '( (A)/(10)=(9)/(15) ) What is the value of ( A ) ?',\n",
       "       '( 2 y=24 ) What is the value of ( y ) ?',\n",
       "       'Calculate ( (2)/(3) x 5 )', 'Which number is the greatest?',\n",
       "       'A bag contains ( 24 ) yellow and green balls. ( (3)/(8) ) of the balls are yellow. How many of the balls are green?',\n",
       "       '( (1)/(3)+(2)/(5)= )',\n",
       "       'Sally has ( (2)/(3) ) of a whole cake in the fridge. Robert eats ( (1)/(3) ) of this piece. What fraction of the whole cake has Robert eaten?\\nChoose the number sentence that would solve the word problem.',\n",
       "       'This is part of a regular polygon. How many sides does it have? [Image: A diagram showing an obtuse angle labelled 144 degrees]',\n",
       "       'What number belongs in the box?\\n(\\n(-8)-(-5)=\\nsquare)',\n",
       "       'Dots have been arranged in these patterns: [Image: Pattern 1 consists of 6 dots, Pattern 2 consists of 10 dots, Pattern 3 consists of 14 dots and Pattern 4 consists of 18 dots] How many dots would there be in Pattern ( 6 ) ?',\n",
       "       'It takes ( 3 ) people a total of ( 192 ) hours to build a wall.\\n\\nHow long would it take if ( 12 ) people built the same wall?',\n",
       "       'The probability of an event occurring is ( 0.9 ).\\n\\nWhich of the following most accurately describes the likelihood of the event occurring?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.QuestionText.apply(convert_latex_to_text).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16dc89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['( (1)/(3) )', '( (3)/(6) )', '( (3)/(8) )', '( (3)/(9) )',\n",
       "       '( 3 )', '( (1)/(12) )', '( (6)/(2) )', '( 24 )', '( 48 )',\n",
       "       '( 60 )', '( 72 )', '( 4 )', '( 6 )', '( 9 )', '( 12 )', '( 22 )',\n",
       "       '( 3 (1)/(3) )', '( 5 (2)/(3) )', '( (10)/(15) )', '( (2)/(15) )',\n",
       "       '( 6.0001 )', '( 6.079 )', '( 6.2 )', '( 15 )', '( 8 )',\n",
       "       '( (11)/(15) )', '( (11)/(30) )', '( (3)/(15) )',\n",
       "       '( (1)/(3) x (2)/(3) )', '( (1)/(3)+(2)/(3) )',\n",
       "       '( (2)/(3) / (1)/(3) )', '( (2)/(3)-(1)/(3) )',\n",
       "       'Not enough information', '( 10 )', '( 5 )', '( -13 )', '( -3 )',\n",
       "       '( 13 )', '( 20 )', '( 26 )', '( 36 )', '( 192 ) hours',\n",
       "       '( 48 ) hours', '( 64 ) hours', '( 768 ) hours', 'Certain',\n",
       "       'Impossible', 'Likely', 'Unlikely'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.MC_Answer.apply(convert_latex_to_text).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73972293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_config():\n",
    "    \"\"\"Setup model configuration for each fold\"\"\"\n",
    "    # LoRA configuration\n",
    "    lora_config = None\n",
    "    if USE_LORA:\n",
    "        R = 8\n",
    "        lora_config = LoraConfig(\n",
    "            r=R,\n",
    "            lora_alpha=R * 4,\n",
    "            target_modules=[\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"down_proj\",\n",
    "                \"up_proj\",\n",
    "                \"gate_proj\",\n",
    "            ],\n",
    "            lora_dropout=0.05,\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            inference_mode=False,\n",
    "        )\n",
    "\n",
    "    # Quantization configuration\n",
    "    q_lora_config = {\"torch_dtype\": torch.bfloat16}\n",
    "    if USE_QLORA:\n",
    "        from transformers import BitsAndBytesConfig\n",
    "\n",
    "        kwargs = {}\n",
    "        if USE_4BIT:\n",
    "            kwargs = {\n",
    "                \"load_in_4bit\": True,\n",
    "                \"bnb_4bit_quant_type\": \"nf4\",\n",
    "                \"bnb_4bit_compute_dtype\": torch.bfloat16,\n",
    "                \"bnb_4bit_use_double_quant\": True,\n",
    "                \"bnb_4bit_quant_storage\": torch.bfloat16,\n",
    "            }\n",
    "        if USE_8BIT:\n",
    "            kwargs = {\"load_in_8bit\": True}\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(**kwargs)\n",
    "        q_lora_config[\"quantization_config\"] = bnb_config\n",
    "\n",
    "    return lora_config, q_lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09fdc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    for obj in list(globals().keys()):\n",
    "        if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "            del globals()[obj]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f70b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map3(predictions, labels):\n",
    "    \"\"\"Calculate MAP@3 score\"\"\"\n",
    "    top3 = np.argsort(-predictions, axis=1)[:, :3]\n",
    "    match = top3 == labels[:, None]\n",
    "    weights = np.array([1.0, 0.5, 1 / 3])\n",
    "    scores = np.sum(match * weights, axis=1)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb86a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_fold(fold_idx, train_idx, val_idx):\n",
    "    \"\"\"Train a single fold\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Training Fold {fold_idx + 1}/{N_FOLDS}\")\n",
    "    print(f\"Train samples: {len(train_idx)}, Val samples: {len(val_idx)}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Create fold datasets\n",
    "    fold_train_df = train_df.iloc[train_idx].copy()\n",
    "    fold_val_df = train_df.iloc[val_idx].copy()\n",
    "\n",
    "    # Prepare string inputs\n",
    "    fold_train_df[\"stringified_input\"] = fold_train_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "    fold_val_df[\"stringified_input\"] = fold_val_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "\n",
    "    # Create HF datasets\n",
    "    train_ds = Dataset.from_pandas(fold_train_df[[\"stringified_input\", \"label\"]])\n",
    "    val_ds = Dataset.from_pandas(fold_val_df[[\"stringified_input\", \"label\"]])\n",
    "\n",
    "    # Setup model\n",
    "    lora_config, q_lora_config = setup_model_config()\n",
    "    seq_model = get_sequence_classifier(MODEL_NAME, n_classes, q_lora_config)\n",
    "    tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "    # Handle padding token\n",
    "    if (\n",
    "        \"gemma\" in MODEL_NAME.lower()\n",
    "        or \"qwen\" in MODEL_NAME.lower()\n",
    "        or \"deepseek-math\" in MODEL_NAME.lower()\n",
    "        or \"llama-3.1\" in MODEL_NAME.lower()\n",
    "        or \"acemath\" in MODEL_NAME.lower()\n",
    "    ):\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        seq_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # Apply PEFT\n",
    "    if USE_QLORA:\n",
    "        seq_model = prepare_model_for_kbit_training(seq_model)\n",
    "\n",
    "    if USE_LORA:\n",
    "        seq_model = get_peft_model(seq_model, lora_config)\n",
    "\n",
    "    # Tokenize datasets\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"stringified_input\"])\n",
    "\n",
    "    train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "    val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "    columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "    train_ds.set_format(type=\"torch\", columns=columns)\n",
    "    val_ds.set_format(type=\"torch\", columns=columns)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = get_training_arguments(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        eval_batch_size=BATCH_SIZE*2,\n",
    "        bf16_support=\"/kaggle\" not in ROOT_PATH,\n",
    "    )\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = get_trainer(\n",
    "        seq_model,\n",
    "        tokenizer,\n",
    "        training_args,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Save fold model\n",
    "    fold_model_path = f\"oof_models/{MODEL_NAME.replace('/', '-')}/fold_{fold_idx}\"\n",
    "    complete_dir = os.path.join(ROOT_PATH, fold_model_path)\n",
    "    if os.path.exists(complete_dir):\n",
    "        shutil.rmtree(complete_dir)\n",
    "    os.makedirs(complete_dir, exist_ok=True)\n",
    "    trainer.save_model(fold_model_path)\n",
    "    tokenizer.save_pretrained(fold_model_path)\n",
    "\n",
    "    # Generate OOF predictions\n",
    "    val_predictions = trainer.predict(val_ds)\n",
    "    val_probs = torch.nn.functional.softmax(\n",
    "        torch.tensor(val_predictions.predictions), dim=1\n",
    "    ).numpy()\n",
    "\n",
    "    # Calculate fold score\n",
    "    val_labels = fold_val_df[\"label\"].values\n",
    "    fold_score = calculate_map3(val_probs, val_labels)\n",
    "\n",
    "    print(f\"Fold {fold_idx + 1} MAP@3: {fold_score:.5f}\")\n",
    "\n",
    "    del seq_model, tokenizer, training_args, trainer\n",
    "    del train_ds, val_ds, fold_train_df, fold_val_df, val_predictions, val_labels\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "\n",
    "    return val_probs, val_idx, fold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002eeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oof_training():\n",
    "    \"\"\"Main OOF training loop\"\"\"\n",
    "    # Setup stratified K-fold\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize OOF predictions\n",
    "    oof_predictions = np.zeros((len(train_df), n_classes))\n",
    "    oof_scores = []\n",
    "\n",
    "    # Train each fold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(train_df, train_df[\"label\"])\n",
    "    ):\n",
    "        val_probs, val_indices, fold_score = train_single_fold(\n",
    "            fold_idx, train_idx, val_idx\n",
    "        )\n",
    "\n",
    "        # Store OOF predictions\n",
    "        oof_predictions[val_indices] = val_probs\n",
    "        oof_scores.append(fold_score)\n",
    "\n",
    "    # Calculate overall OOF score\n",
    "    overall_score = calculate_map3(oof_predictions, train_df[\"label\"].values)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"OOF TRAINING COMPLETED\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Individual Fold Scores: {[f'{score:.5f}' for score in oof_scores]}\")\n",
    "    print(f\"Mean Fold Score: {np.mean(oof_scores):.5f} ± {np.std(oof_scores):.5f}\")\n",
    "    print(f\"Overall OOF Score: {overall_score:.5f}\")\n",
    "\n",
    "    # Save OOF predictions\n",
    "    oof_df = pd.DataFrame(\n",
    "        oof_predictions, columns=[f\"pred_{i}\" for i in range(n_classes)]\n",
    "    )\n",
    "    oof_df[\"true_label\"] = train_df[\"label\"].values\n",
    "    oof_df[\"predict\"] = train_df[\"predict\"].values\n",
    "    oof_df[\"fold_score\"] = 0\n",
    "\n",
    "    # Add fold information\n",
    "    fold_info = np.zeros(len(train_df))\n",
    "    for fold_idx, (_, val_idx) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
    "        fold_info[val_idx] = fold_idx\n",
    "    oof_df[\"fold\"] = fold_info\n",
    "\n",
    "    oof_df.to_csv(\"oof_predictions.csv\", index=False)\n",
    "\n",
    "    return oof_predictions, oof_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2da980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Fold 1/5\n",
      "Train samples: 29356, Val samples: 7340\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36c6a9bbfa64d96a987a767b6d02f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-1.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65c1a83deaf4d5c848d8b9059996e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ad3aa940cc4d7084a98a38a6c4b230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7340 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 48:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.558372</td>\n",
       "      <td>0.897184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.434443</td>\n",
       "      <td>0.915168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.357410</td>\n",
       "      <td>0.932039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.382279</td>\n",
       "      <td>0.933084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>0.373227</td>\n",
       "      <td>0.936081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.381214</td>\n",
       "      <td>0.938783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.375592</td>\n",
       "      <td>0.939214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.506831</td>\n",
       "      <td>0.938783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.522892</td>\n",
       "      <td>0.938806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.531738</td>\n",
       "      <td>0.938579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.531908</td>\n",
       "      <td>0.938692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MAP@3: 0.93921\n",
      "\n",
      "============================================================\n",
      "Training Fold 2/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a5caf26e614744be9fec24b219f526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-1.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87520bb83042491a8e5ca72b4c0c0a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd45e0b2af15434fb1132d91ec0de29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 48:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.901894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.415724</td>\n",
       "      <td>0.922083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.365327</td>\n",
       "      <td>0.932893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.428993</td>\n",
       "      <td>0.933347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.418471</td>\n",
       "      <td>0.936549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.400257</td>\n",
       "      <td>0.937798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>0.939615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.569237</td>\n",
       "      <td>0.938343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.598824</td>\n",
       "      <td>0.936958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.603218</td>\n",
       "      <td>0.937457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.602729</td>\n",
       "      <td>0.937889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 MAP@3: 0.93961\n",
      "\n",
      "============================================================\n",
      "Training Fold 3/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa80bcd164741729d5478fa0fc14dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-1.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8071b982b1d54115a7c0164808838fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbc4647c20944dcad14cf73e2e00df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 48:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.586531</td>\n",
       "      <td>0.896353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.465239</td>\n",
       "      <td>0.916406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>0.382423</td>\n",
       "      <td>0.927420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.244900</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.934255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.384353</td>\n",
       "      <td>0.935323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.377955</td>\n",
       "      <td>0.937889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.366669</td>\n",
       "      <td>0.938638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.448996</td>\n",
       "      <td>0.939547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.476443</td>\n",
       "      <td>0.940228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.481784</td>\n",
       "      <td>0.940273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.481853</td>\n",
       "      <td>0.940183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 MAP@3: 0.94027\n",
      "\n",
      "============================================================\n",
      "Training Fold 4/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6c8e820c9747c095d862d14ca41213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-1.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126cc665cb904a5a9d3f6cc756952418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f5c8da64e54de7b1e1435ce5b1dd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 48:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>0.575692</td>\n",
       "      <td>0.894854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.476800</td>\n",
       "      <td>0.416551</td>\n",
       "      <td>0.920857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.374286</td>\n",
       "      <td>0.927306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.362723</td>\n",
       "      <td>0.937139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.378656</td>\n",
       "      <td>0.937866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.940228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.941681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.438147</td>\n",
       "      <td>0.941182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.468188</td>\n",
       "      <td>0.940160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.474221</td>\n",
       "      <td>0.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.474817</td>\n",
       "      <td>0.939955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 MAP@3: 0.94168\n",
      "\n",
      "============================================================\n",
      "Training Fold 5/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407026573bf740d0968b27473937c592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-1.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafd6f4a58d045d986e94847c8cba46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eeecda883c4e20a3b8575eb0aa9348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 48:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.638200</td>\n",
       "      <td>0.515695</td>\n",
       "      <td>0.900123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.406175</td>\n",
       "      <td>0.924899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.367722</td>\n",
       "      <td>0.929350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.937980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.382201</td>\n",
       "      <td>0.939615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.370689</td>\n",
       "      <td>0.941432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.386019</td>\n",
       "      <td>0.942272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>0.522605</td>\n",
       "      <td>0.938275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.533708</td>\n",
       "      <td>0.941182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.940955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 MAP@3: 0.94227\n",
      "\n",
      "============================================================\n",
      "OOF TRAINING COMPLETED\n",
      "============================================================\n",
      "Individual Fold Scores: ['0.93921', '0.93961', '0.94027', '0.94168', '0.94227']\n",
      "Mean Fold Score: 0.94061 ± 0.00118\n",
      "Overall OOF Score: 0.94061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "oof_predictions, oof_scores = run_oof_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b67cde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions():\n",
    "    \"\"\"Generate test predictions using all fold models\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"GENERATING TEST PREDICTIONS\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Prepare test data\n",
    "    test_df[\"stringified_input\"] = test_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "\n",
    "    all_test_predictions = []\n",
    "\n",
    "    for fold_idx in range(N_FOLDS):\n",
    "        print(f\"Loading fold {fold_idx + 1} model...\")\n",
    "\n",
    "        # Load tokenizer\n",
    "        model_path = model_path = os.path.join(\n",
    "            ROOT_PATH,\n",
    "            \"oof_models\",\n",
    "            MODEL_NAME.replace(\"/\", \"-\"),\n",
    "            f\"fold_{fold_idx}\",\n",
    "        )\n",
    "        if USE_LORA:\n",
    "            model_path = MODEL_NAME\n",
    "        tokenizer = get_tokenizer(model_path)\n",
    "\n",
    "        # Prepare test dataset\n",
    "        test_ds = Dataset.from_pandas(test_df[[\"stringified_input\"]])\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[\"stringified_input\"])\n",
    "\n",
    "        test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "        # Load model and generate predictions\n",
    "        lora_config, q_lora_config = setup_model_config()\n",
    "        seq_model = get_sequence_classifier(model_path, n_classes, q_lora_config)\n",
    "\n",
    "        # Handle padding token\n",
    "        if (\n",
    "            \"gemma\" in MODEL_NAME.lower()\n",
    "            or \"qwen\" in MODEL_NAME.lower()\n",
    "            or \"deepseek-math\" in MODEL_NAME.lower()\n",
    "            or \"llama-3.1\" in MODEL_NAME.lower()\n",
    "            or \"acemath\" in MODEL_NAME.lower()\n",
    "        ):\n",
    "            if tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            seq_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "        if USE_LORA:\n",
    "            fold_model_path = os.path.join(\n",
    "                ROOT_PATH,\n",
    "                \"oof_models\",\n",
    "                MODEL_NAME.replace(\"/\", \"-\"),\n",
    "                f\"fold_{fold_idx}\",\n",
    "            )\n",
    "            seq_model = PeftModel.from_pretrained(seq_model, fold_model_path)\n",
    "\n",
    "        # Create trainer for inference\n",
    "        training_args = get_training_arguments(\n",
    "            bf16_support=\"/kaggle\" not in ROOT_PATH,\n",
    "            train_on_full_dataset=True,  # No validation needed for inference\n",
    "        )\n",
    "        trainer = get_trainer(seq_model, tokenizer, training_args, test_ds, test_ds)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = trainer.predict(test_ds)\n",
    "        probs = torch.nn.functional.softmax(\n",
    "            torch.tensor(predictions.predictions), dim=1\n",
    "        ).numpy()\n",
    "\n",
    "        all_test_predictions.append(probs)\n",
    "\n",
    "        # Clean up\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "\n",
    "    # Ensemble predictions (simple average)\n",
    "    ensemble_predictions = np.mean(all_test_predictions, axis=0)\n",
    "\n",
    "    # Generate submission\n",
    "    topk = np.argsort(-ensemble_predictions, axis=1)[:, :TOP_K]\n",
    "    flat_topk = topk.flatten()\n",
    "    decoded_labels = le.inverse_transform(flat_topk)\n",
    "    topk_labels = decoded_labels.reshape(topk.shape)\n",
    "\n",
    "    joined_preds = [\" \".join(row) for row in topk_labels]\n",
    "\n",
    "    submission = pd.DataFrame(\n",
    "        {\"row_id\": test_df.row_id.values, \"Category:Misconception\": joined_preds}\n",
    "    )\n",
    "    submission.to_csv(\"oof_submission.csv\", index=False)\n",
    "\n",
    "    print(\"Test predictions saved to 'oof_submission.csv'\")\n",
    "    return ensemble_predictions, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f6c41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING TEST PREDICTIONS\n",
      "============================================================\n",
      "Loading fold 1 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f833ac829847209642dad56b6b8395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 2 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e0b633fe484d7c844d91c6be2c52b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 3 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ed1d3816d4e97992173a3422f9398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 4 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b88f875fd14188897ab8bd255b28f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 5 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1deb4aaa18784f4084a6ecc5aaee8179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to 'oof_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "test_predictions, submission = generate_test_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1f2fb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Category:Misconception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36696</td>\n",
       "      <td>True_Correct:NA True_Neither:NA True_Misconcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36697</td>\n",
       "      <td>False_Misconception:WNB False_Neither:NA False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36698</td>\n",
       "      <td>True_Neither:NA True_Correct:NA True_Misconcep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                             Category:Misconception\n",
       "0   36696  True_Correct:NA True_Neither:NA True_Misconcep...\n",
       "1   36697  False_Misconception:WNB False_Neither:NA False...\n",
       "2   36698  True_Neither:NA True_Correct:NA True_Misconcep..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd45b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
