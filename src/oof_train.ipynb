{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a9878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import gc\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "if \"/kaggle\" in ROOT_PATH:\n",
    "    ROOT_PATH = \"/kaggle/input\"\n",
    "    sys.path.append(os.path.join(ROOT_PATH, \"map-utilities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdd51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel,\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    stringify_input,\n",
    "    get_model_name,\n",
    "    get_sequence_classifier,\n",
    "    get_tokenizer,\n",
    "    get_training_arguments,\n",
    "    get_trainer,\n",
    "    convert_latex_to_text,\n",
    "    compute_map3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_MODEL = \"microsoft/deberta-v3-large\"\n",
    "# BASE_MODEL = \"answerdotai/ModernBERT-large\"\n",
    "BASE_MODEL = \"jhu-clsp/ettin-encoder-1b\"\n",
    "# BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "# BASE_MODEL = \"google/gemma-2-9b-it\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-1.7B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-8B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-14B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "# BASE_MODEL = \"Qwen/Qwen2.5-Coder-14B-Instruct\"\n",
    "# BASE_MODEL = \"deepseek-ai/deepseek-math-7b-instruct\"\n",
    "# BASE_MODEL = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\n",
    "# BASE_MODEL = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-Embedding-4B\"\n",
    "# BASE_MODEL = \"Qwen/Qwen3-Embedding-8B\"\n",
    "# BASE_MODEL = \"nvidia/AceMath-1.5B-Instruct\"\n",
    "# BASE_MODEL = \"nvidia/AceReason-Nemotron-1.1-7B\"\n",
    "# BASE_MODEL = \"nvidia/AceReason-Nemotron-14B\"\n",
    "# BASE_MODEL = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# BASE_MODEL = \"google/t5gemma-l-l-ul2-it\"\n",
    "# BASE_MODEL = \"google/t5gemma-2b-2b-ul2-it\"\n",
    "# BASE_MODEL = \"google/t5gemma-9b-2b-ul2-it\"\n",
    "# BASE_MODEL = \"google/gemma-3-1b-it\"\n",
    "# BASE_MODEL = \"google/gemma-3-12b-it\"\n",
    "\n",
    "N_FOLDS = 5\n",
    "SPLIT_RATIO = 0.2\n",
    "MAX_LEN = 256\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 4e-5\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = get_model_name(\"/kaggle\" in ROOT_PATH, ROOT_PATH, BASE_MODEL)\n",
    "\n",
    "USE_LORA = False\n",
    "USE_QLORA = False\n",
    "BITS = 4\n",
    "USE_4BIT = BITS == 4\n",
    "USE_8BIT = BITS == 8\n",
    "\n",
    "TRAIN_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"train.csv\")\n",
    "TEST_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737e7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ec8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (36696, 7)\n",
      "Testing Shape: (3, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape:\", train_df.shape)\n",
    "print(\"Testing Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defda15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Misconception = train_df.Misconception.fillna(\"NA\")\n",
    "train_df[\"predict\"] = train_df.Category + \":\" + train_df.Misconception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9836c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386488/1307861462.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df.is_mc_answer_correct = train_df.is_mc_answer_correct.fillna(False)\n",
      "/tmp/ipykernel_386488/1307861462.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df.is_mc_answer_correct = test_df.is_mc_answer_correct.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "idx = train_df.Category.str.contains(\"True\", case=False)\n",
    "tmp = train_df.loc[idx].copy()\n",
    "tmp[\"c\"] = tmp.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "tmp = tmp.sort_values(\"c\", ascending=False)\n",
    "tmp = tmp.drop_duplicates([\"QuestionId\"])\n",
    "tmp = tmp[[\"QuestionId\", \"MC_Answer\"]]\n",
    "tmp[\"is_mc_answer_correct\"] = True\n",
    "\n",
    "train_df = train_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "train_df.is_mc_answer_correct = train_df.is_mc_answer_correct.fillna(False)\n",
    "\n",
    "test_df = test_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "test_df.is_mc_answer_correct = test_df.is_mc_answer_correct.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82e38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"is_student_explanation_correct\"] = train_df.Category.apply(\n",
    "    lambda x: 0 if \"Neither\" in x else (1 if \"Correct\" in x else 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f3a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (36696, 11) with 65 predict classes\n"
     ]
    }
   ],
   "source": [
    "# le = LabelEncoder()\n",
    "le = joblib.load(os.path.join(ROOT_PATH, \"label_encoder.joblib\"))\n",
    "\n",
    "train_df[\"label\"] = le.transform(train_df[\"predict\"])\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train_df.shape} with {n_classes} predict classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af5b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>MC_Answer</th>\n",
       "      <th>StudentExplanation</th>\n",
       "      <th>Category</th>\n",
       "      <th>Misconception</th>\n",
       "      <th>predict</th>\n",
       "      <th>is_mc_answer_correct</th>\n",
       "      <th>is_student_explanation_correct</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>0ne third is equal to tree nineth</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 3rd is half of 3 6th, so it is simplee to un...</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Neither:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 goes into everything and 3 goes into nine</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Neither:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 out of every 3 isn't coloured</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>NA</td>\n",
       "      <td>True_Correct:NA</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  QuestionId                                       QuestionText  \\\n",
       "0       0       31772  What fraction of the shape is not shaded? Give...   \n",
       "1       1       31772  What fraction of the shape is not shaded? Give...   \n",
       "2       2       31772  What fraction of the shape is not shaded? Give...   \n",
       "3       3       31772  What fraction of the shape is not shaded? Give...   \n",
       "4       4       31772  What fraction of the shape is not shaded? Give...   \n",
       "\n",
       "           MC_Answer                                 StudentExplanation  \\\n",
       "0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n",
       "1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n",
       "2  \\( \\frac{1}{3} \\)  1 3rd is half of 3 6th, so it is simplee to un...   \n",
       "3  \\( \\frac{1}{3} \\)        1 goes into everything and 3 goes into nine   \n",
       "4  \\( \\frac{1}{3} \\)                    1 out of every 3 isn't coloured   \n",
       "\n",
       "       Category Misconception          predict  is_mc_answer_correct  \\\n",
       "0  True_Correct            NA  True_Correct:NA                  True   \n",
       "1  True_Correct            NA  True_Correct:NA                  True   \n",
       "2  True_Neither            NA  True_Neither:NA                  True   \n",
       "3  True_Neither            NA  True_Neither:NA                  True   \n",
       "4  True_Correct            NA  True_Correct:NA                  True   \n",
       "\n",
       "   is_student_explanation_correct  label  \n",
       "0                               1     37  \n",
       "1                               1     37  \n",
       "2                               0     64  \n",
       "3                               0     64  \n",
       "4                               1     37  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93ee45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.]',\n",
       "       'Calculate ( (1)/(2) / 6 )',\n",
       "       'A box contains ( 120 ) counters. The counters are red or blue. ( (3)/(5) ) of the counters are red.\\nHow many red counters are there?',\n",
       "       '( (A)/(10)=(9)/(15) ) What is the value of ( A ) ?',\n",
       "       '( 2 y=24 ) What is the value of ( y ) ?',\n",
       "       'Calculate ( (2)/(3) x 5 )', 'Which number is the greatest?',\n",
       "       'A bag contains ( 24 ) yellow and green balls. ( (3)/(8) ) of the balls are yellow. How many of the balls are green?',\n",
       "       '( (1)/(3)+(2)/(5)= )',\n",
       "       'Sally has ( (2)/(3) ) of a whole cake in the fridge. Robert eats ( (1)/(3) ) of this piece. What fraction of the whole cake has Robert eaten?\\nChoose the number sentence that would solve the word problem.',\n",
       "       'This is part of a regular polygon. How many sides does it have? [Image: A diagram showing an obtuse angle labelled 144 degrees]',\n",
       "       'What number belongs in the box?\\n(\\n(-8)-(-5)=\\nsquare)',\n",
       "       'Dots have been arranged in these patterns: [Image: Pattern 1 consists of 6 dots, Pattern 2 consists of 10 dots, Pattern 3 consists of 14 dots and Pattern 4 consists of 18 dots] How many dots would there be in Pattern ( 6 ) ?',\n",
       "       'It takes ( 3 ) people a total of ( 192 ) hours to build a wall.\\n\\nHow long would it take if ( 12 ) people built the same wall?',\n",
       "       'The probability of an event occurring is ( 0.9 ).\\n\\nWhich of the following most accurately describes the likelihood of the event occurring?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.QuestionText.apply(convert_latex_to_text).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16dc89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['( (1)/(3) )', '( (3)/(6) )', '( (3)/(8) )', '( (3)/(9) )',\n",
       "       '( 3 )', '( (1)/(12) )', '( (6)/(2) )', '( 24 )', '( 48 )',\n",
       "       '( 60 )', '( 72 )', '( 4 )', '( 6 )', '( 9 )', '( 12 )', '( 22 )',\n",
       "       '( 3 (1)/(3) )', '( 5 (2)/(3) )', '( (10)/(15) )', '( (2)/(15) )',\n",
       "       '( 6.0001 )', '( 6.079 )', '( 6.2 )', '( 15 )', '( 8 )',\n",
       "       '( (11)/(15) )', '( (11)/(30) )', '( (3)/(15) )',\n",
       "       '( (1)/(3) x (2)/(3) )', '( (1)/(3)+(2)/(3) )',\n",
       "       '( (2)/(3) / (1)/(3) )', '( (2)/(3)-(1)/(3) )',\n",
       "       'Not enough information', '( 10 )', '( 5 )', '( -13 )', '( -3 )',\n",
       "       '( 13 )', '( 20 )', '( 26 )', '( 36 )', '( 192 ) hours',\n",
       "       '( 48 ) hours', '( 64 ) hours', '( 768 ) hours', 'Certain',\n",
       "       'Impossible', 'Likely', 'Unlikely'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.MC_Answer.apply(convert_latex_to_text).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73972293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_config():\n",
    "    \"\"\"Setup model configuration for each fold\"\"\"\n",
    "    # LoRA configuration\n",
    "    lora_config = None\n",
    "    if USE_LORA:\n",
    "        R = 8\n",
    "        lora_config = LoraConfig(\n",
    "            r=R,\n",
    "            lora_alpha=R * 4,\n",
    "            target_modules=[\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"down_proj\",\n",
    "                \"up_proj\",\n",
    "                \"gate_proj\",\n",
    "            ],\n",
    "            lora_dropout=0.05,\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            inference_mode=False,\n",
    "        )\n",
    "\n",
    "    # Quantization configuration\n",
    "    q_lora_config = {\"torch_dtype\": torch.bfloat16}\n",
    "    if USE_QLORA:\n",
    "        from transformers import BitsAndBytesConfig\n",
    "\n",
    "        kwargs = {}\n",
    "        if USE_4BIT:\n",
    "            kwargs = {\n",
    "                \"load_in_4bit\": True,\n",
    "                \"bnb_4bit_quant_type\": \"nf4\",\n",
    "                \"bnb_4bit_compute_dtype\": torch.bfloat16,\n",
    "                \"bnb_4bit_use_double_quant\": True,\n",
    "                \"bnb_4bit_quant_storage\": torch.bfloat16,\n",
    "            }\n",
    "        if USE_8BIT:\n",
    "            kwargs = {\"load_in_8bit\": True}\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(**kwargs)\n",
    "        q_lora_config[\"quantization_config\"] = bnb_config\n",
    "\n",
    "    return lora_config, q_lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09fdc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    for obj in list(globals().keys()):\n",
    "        if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "            del globals()[obj]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f70b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map3(predictions, labels):\n",
    "    \"\"\"Calculate MAP@3 score\"\"\"\n",
    "    top3 = np.argsort(-predictions, axis=1)[:, :3]\n",
    "    match = top3 == labels[:, None]\n",
    "    weights = np.array([1.0, 0.5, 1 / 3])\n",
    "    scores = np.sum(match * weights, axis=1)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb86a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_fold(fold_idx, train_idx, val_idx):\n",
    "    \"\"\"Train a single fold\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Training Fold {fold_idx + 1}/{N_FOLDS}\")\n",
    "    print(f\"Train samples: {len(train_idx)}, Val samples: {len(val_idx)}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Create fold datasets\n",
    "    fold_train_df = train_df.iloc[train_idx].copy()\n",
    "    fold_val_df = train_df.iloc[val_idx].copy()\n",
    "\n",
    "    # Prepare string inputs\n",
    "    fold_train_df[\"stringified_input\"] = fold_train_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "    fold_val_df[\"stringified_input\"] = fold_val_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "\n",
    "    # Create HF datasets\n",
    "    train_ds = Dataset.from_pandas(fold_train_df[[\"stringified_input\", \"label\"]])\n",
    "    val_ds = Dataset.from_pandas(fold_val_df[[\"stringified_input\", \"label\"]])\n",
    "\n",
    "    # Setup model\n",
    "    lora_config, q_lora_config = setup_model_config()\n",
    "    seq_model = get_sequence_classifier(MODEL_NAME, n_classes, q_lora_config)\n",
    "    tokenizer = get_tokenizer(MODEL_NAME)\n",
    "\n",
    "    # Handle padding token\n",
    "    if (\n",
    "        \"gemma\" in MODEL_NAME.lower()\n",
    "        or \"qwen\" in MODEL_NAME.lower()\n",
    "        or \"deepseek-math\" in MODEL_NAME.lower()\n",
    "        or \"llama-3.1\" in MODEL_NAME.lower()\n",
    "        or \"acemath\" in MODEL_NAME.lower()\n",
    "    ):\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        seq_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # Apply PEFT\n",
    "    if USE_QLORA:\n",
    "        seq_model = prepare_model_for_kbit_training(seq_model)\n",
    "\n",
    "    if USE_LORA:\n",
    "        seq_model = get_peft_model(seq_model, lora_config)\n",
    "\n",
    "    # Tokenize datasets\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"stringified_input\"])\n",
    "\n",
    "    train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "    val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "    columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "    train_ds.set_format(type=\"torch\", columns=columns)\n",
    "    val_ds.set_format(type=\"torch\", columns=columns)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = get_training_arguments(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "        eval_batch_size=BATCH_SIZE*2,\n",
    "        bf16_support=\"/kaggle\" not in ROOT_PATH,\n",
    "    )\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = get_trainer(\n",
    "        seq_model,\n",
    "        tokenizer,\n",
    "        training_args,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Save fold model\n",
    "    fold_model_path = f\"oof_models/{MODEL_NAME.replace('/', '-')}/fold_{fold_idx}\"\n",
    "    complete_dir = os.path.join(ROOT_PATH, fold_model_path)\n",
    "    if os.path.exists(complete_dir):\n",
    "        shutil.rmtree(complete_dir)\n",
    "    os.makedirs(complete_dir, exist_ok=True)\n",
    "    trainer.save_model(fold_model_path)\n",
    "    tokenizer.save_pretrained(fold_model_path)\n",
    "\n",
    "    # Generate OOF predictions\n",
    "    val_predictions = trainer.predict(val_ds)\n",
    "    val_probs = torch.nn.functional.softmax(\n",
    "        torch.tensor(val_predictions.predictions), dim=1\n",
    "    ).numpy()\n",
    "\n",
    "    # Calculate fold score\n",
    "    val_labels = fold_val_df[\"label\"].values\n",
    "    fold_score = calculate_map3(val_probs, val_labels)\n",
    "\n",
    "    print(f\"Fold {fold_idx + 1} MAP@3: {fold_score:.5f}\")\n",
    "\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "    clear_memory()\n",
    "\n",
    "    return val_probs, val_idx, fold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002eeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oof_training():\n",
    "    \"\"\"Main OOF training loop\"\"\"\n",
    "    # Setup stratified K-fold\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize OOF predictions\n",
    "    oof_predictions = np.zeros((len(train_df), n_classes))\n",
    "    oof_scores = []\n",
    "\n",
    "    # Train each fold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(train_df, train_df[\"label\"])\n",
    "    ):\n",
    "        val_probs, val_indices, fold_score = train_single_fold(\n",
    "            fold_idx, train_idx, val_idx\n",
    "        )\n",
    "\n",
    "        # Store OOF predictions\n",
    "        oof_predictions[val_indices] = val_probs\n",
    "        oof_scores.append(fold_score)\n",
    "\n",
    "    # Calculate overall OOF score\n",
    "    overall_score = calculate_map3(oof_predictions, train_df[\"label\"].values)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"OOF TRAINING COMPLETED\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Individual Fold Scores: {[f'{score:.5f}' for score in oof_scores]}\")\n",
    "    print(f\"Mean Fold Score: {np.mean(oof_scores):.5f} Â± {np.std(oof_scores):.5f}\")\n",
    "    print(f\"Overall OOF Score: {overall_score:.5f}\")\n",
    "\n",
    "    # Save OOF predictions\n",
    "    oof_df = pd.DataFrame(\n",
    "        oof_predictions, columns=[f\"pred_{i}\" for i in range(n_classes)]\n",
    "    )\n",
    "    oof_df[\"true_label\"] = train_df[\"label\"].values\n",
    "    oof_df[\"predict\"] = train_df[\"predict\"].values\n",
    "    oof_df[\"fold_score\"] = 0\n",
    "\n",
    "    # Add fold information\n",
    "    fold_info = np.zeros(len(train_df))\n",
    "    for fold_idx, (_, val_idx) in enumerate(skf.split(train_df, train_df[\"label\"])):\n",
    "        fold_info[val_idx] = fold_idx\n",
    "    oof_df[\"fold\"] = fold_info\n",
    "\n",
    "    oof_df.to_csv(\"oof_predictions.csv\", index=False)\n",
    "\n",
    "    return oof_predictions, oof_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2da980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maitri/Downloads/dev/map-kaggle-competition/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Fold 1/5\n",
      "Train samples: 29356, Val samples: 7340\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/ettin-encoder-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b775dbdccf4e4f937e4a76143c70f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c23859f8fd4e38ae6aeed1849e7f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7340 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maitri/Downloads/dev/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5505' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5505/5505 13:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.496532</td>\n",
       "      <td>0.904905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.408019</td>\n",
       "      <td>0.920391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.360637</td>\n",
       "      <td>0.934559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.371899</td>\n",
       "      <td>0.936081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.220100</td>\n",
       "      <td>0.354624</td>\n",
       "      <td>0.937080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.359530</td>\n",
       "      <td>0.939623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.356327</td>\n",
       "      <td>0.939555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.940304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.940645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.408283</td>\n",
       "      <td>0.940622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.408417</td>\n",
       "      <td>0.940895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MAP@3: 0.94089\n",
      "\n",
      "============================================================\n",
      "Training Fold 2/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/ettin-encoder-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ac45fe40b041bb8df464e878f7e64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977432408a0449bc8f6ab05e168566d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maitri/Downloads/dev/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5500' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5500/5505 13:17 < 00:00, 6.90 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.477919</td>\n",
       "      <td>0.909093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.407976</td>\n",
       "      <td>0.926012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.934846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.388818</td>\n",
       "      <td>0.933665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.375023</td>\n",
       "      <td>0.937662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.365567</td>\n",
       "      <td>0.939047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.367790</td>\n",
       "      <td>0.937616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.401329</td>\n",
       "      <td>0.938797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.424795</td>\n",
       "      <td>0.938252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.427727</td>\n",
       "      <td>0.938502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.428184</td>\n",
       "      <td>0.938389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 MAP@3: 0.93905\n",
      "\n",
      "============================================================\n",
      "Training Fold 3/5\n",
      "Train samples: 29357, Val samples: 7339\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/ettin-encoder-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62f691ef8c74eeda6887b6c5662763b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca0809b151f48a586bdcf43d2b25270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7339 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maitri/Downloads/dev/map-kaggle-competition/src/utils.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1048' max='5505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1048/5505 02:27 < 10:26, 7.11 it/s, Epoch 0.57/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Map@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.470341</td>\n",
       "      <td>0.912613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>0.454169</td>\n",
       "      <td>0.921129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_predictions, oof_scores = run_oof_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions():\n",
    "    \"\"\"Generate test predictions using all fold models\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"GENERATING TEST PREDICTIONS\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Prepare test data\n",
    "    test_df[\"stringified_input\"] = test_df.apply(\n",
    "        lambda row: stringify_input(row, MODEL_NAME), axis=1\n",
    "    )\n",
    "\n",
    "    all_test_predictions = []\n",
    "\n",
    "    for fold_idx in range(N_FOLDS):\n",
    "        print(f\"Loading fold {fold_idx + 1} model...\")\n",
    "\n",
    "        # Load tokenizer\n",
    "        fold_model_path = f\"oof_models/{MODEL_NAME.replace('/', '-')}/fold_{fold_idx}\"\n",
    "        tokenizer = get_tokenizer(fold_model_path)\n",
    "\n",
    "        # Prepare test dataset\n",
    "        test_ds = Dataset.from_pandas(test_df[[\"stringified_input\"]])\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[\"stringified_input\"])\n",
    "\n",
    "        test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "        # Load model and generate predictions\n",
    "        lora_config, q_lora_config = setup_model_config()\n",
    "        seq_model = get_sequence_classifier(MODEL_NAME, n_classes, q_lora_config)\n",
    "\n",
    "        if USE_LORA:\n",
    "            seq_model = PeftModel.from_pretrained(seq_model, fold_model_path)\n",
    "\n",
    "        # Create trainer for inference\n",
    "        training_args = get_training_arguments(\n",
    "            bf16_support=\"/kaggle\" not in ROOT_PATH,\n",
    "            train_on_full_dataset=True,  # No validation needed for inference\n",
    "        )\n",
    "        trainer = get_trainer(seq_model, tokenizer, training_args, test_ds, test_ds)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = trainer.predict(test_ds)\n",
    "        probs = torch.nn.functional.softmax(\n",
    "            torch.tensor(predictions.predictions), dim=1\n",
    "        ).numpy()\n",
    "\n",
    "        all_test_predictions.append(probs)\n",
    "\n",
    "        # Clean up\n",
    "        del seq_model, trainer, test_ds\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Ensemble predictions (simple average)\n",
    "    ensemble_predictions = np.mean(all_test_predictions, axis=0)\n",
    "\n",
    "    # Generate submission\n",
    "    top3 = np.argsort(-ensemble_predictions, axis=1)[:, :3]\n",
    "    flat_top3 = top3.flatten()\n",
    "    decoded_labels = le.inverse_transform(flat_top3)\n",
    "    top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "    joined_preds = [\" \".join(row) for row in top3_labels]\n",
    "\n",
    "    submission = pd.DataFrame(\n",
    "        {\"row_id\": test_df.row_id.values, \"Category:Misconception\": joined_preds}\n",
    "    )\n",
    "    submission.to_csv(\"oof_submission.csv\", index=False)\n",
    "\n",
    "    print(\"Test predictions saved to 'oof_submission.csv'\")\n",
    "    return ensemble_predictions, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, submission = generate_test_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2fb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
