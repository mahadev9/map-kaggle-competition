{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-deps /kaggle/input/map-utilities/transformers-4.55.3-py3-none-any.whl\n",
    "!pip install --no-deps /kaggle/input/map-utilities/bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl\n",
    "!pip install --no-deps /kaggle/input/map-utilities/peft-0.17.1-py3-none-any.whl\n",
    "!pip install --no-deps /kaggle/input/map-utilities/datasets-4.0.0-py3-none-any.whl\n",
    "!pip install --no-deps /kaggle/input/map-utilities/huggingface_hub-0.34.4-py3-none-any.whl\n",
    "!pip install --no-deps /kaggle/input/map-utilities/accelerate-1.10.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "if \"/kaggle\" in ROOT_PATH:\n",
    "    ROOT_PATH = \"/kaggle/input\"\n",
    "    sys.path.append(os.path.join(ROOT_PATH, \"map-utilities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import PeftModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from utils import (\n",
    "    stringify_input,\n",
    "    get_model_name,\n",
    "    get_sequence_classifier,\n",
    "    get_tokenizer,\n",
    "    get_training_arguments,\n",
    "    get_trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf84d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = joblib.load(os.path.join(ROOT_PATH, \"map-utilities\", \"label_encoder.joblib\"))\n",
    "n_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d60918",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "TOP_K = 10\n",
    "\n",
    "BITS = 4\n",
    "USE_4BIT = BITS == 4\n",
    "USE_8BIT = BITS == 8\n",
    "\n",
    "MODEL_VARIATIONS = [\n",
    "    {\n",
    "        \"model_name\": get_model_name(\n",
    "            \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"deepseek-math/pytorch/deepseek-math-7b-instruct/1\"\n",
    "        ),\n",
    "        \"adapter_path\": get_model_name(\n",
    "            \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"deepseek-math-7b-instruct-qlora-4bit/transformers/default/2\"\n",
    "        ),\n",
    "        \"submission_file\": \"submission_deepseek_math_7b.csv\",\n",
    "        \"use_lora\": True,\n",
    "        \"use_qlora\": False,\n",
    "        \"n_fold\": 5,\n",
    "    },\n",
    "    # {\n",
    "    #     \"model_name\": get_model_name(\n",
    "    #         \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"gemma-2/transformers/gemma-2-9b-it/2\"\n",
    "    #     ),\n",
    "    #     \"adapter_path\": get_model_name(\n",
    "    #         \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"gemma2-9b-it-qlora-4bit/transformers/default/2\"\n",
    "    #     ),\n",
    "    #     \"submission_file\": \"submission_gemma2_9b.csv\",\n",
    "    #     \"use_lora\": True,\n",
    "    #     \"use_qlora\": False,\n",
    "    #     \"n_fold\": 5,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model_name\": get_model_name(\n",
    "    #         \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"qwen-3-embedding/transformers/4b/1\"\n",
    "    #     ),\n",
    "    #     \"adapter_path\": get_model_name(\n",
    "    #         \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"qwen3-embedding-4b-qlora-4bit/transformers/default/1\"\n",
    "    #     ),\n",
    "    #     \"submission_file\": \"submission_qwen3_embedding_4b.csv\",\n",
    "    #     \"use_lora\": True,\n",
    "    #     \"use_qlora\": False,\n",
    "    #     \"n_fold\": 5,\n",
    "    # },\n",
    "    {\n",
    "        \"model_name\": get_model_name(\n",
    "            \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"ettin-encoder-1b/transformers/default/6\"\n",
    "        ),\n",
    "        \"adapter_path\": get_model_name(\n",
    "            \"/kaggle\" in ROOT_PATH, ROOT_PATH, \"ettin-encoder-1b/transformers/default/6\"\n",
    "        ),\n",
    "        \"submission_file\": \"submission_ettin_1b.csv\",\n",
    "        \"use_lora\": False,\n",
    "        \"use_qlora\": False,\n",
    "        \"n_fold\": 5,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"train.csv\")\n",
    "TEST_PATH = os.path.join(ROOT_PATH, \"map-charting-student-math-misunderstandings\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de47934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Shape:\", train_df.shape)\n",
    "print(\"Testing Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_df.Category.str.contains(\"True\", case=False)\n",
    "tmp = train_df.loc[idx].copy()\n",
    "tmp[\"c\"] = tmp.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "tmp = tmp.sort_values(\"c\", ascending=False)\n",
    "tmp = tmp.drop_duplicates([\"QuestionId\"])\n",
    "tmp = tmp[[\"QuestionId\", \"MC_Answer\"]]\n",
    "tmp[\"is_mc_answer_correct\"] = True\n",
    "\n",
    "train_df = train_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "train_df.is_mc_answer_correct = train_df.is_mc_answer_correct.fillna(False)\n",
    "\n",
    "test_df = test_df.merge(tmp, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "test_df.is_mc_answer_correct = test_df.is_mc_answer_correct.fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    for obj in list(globals().keys()):\n",
    "        if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "            del globals()[obj]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97702e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(model_name, adapter_path, use_lora, n_fold, submission_file):\n",
    "    \"\"\"Generate test predictions using all fold models\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"GENERATING TEST PREDICTIONS\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Prepare test data\n",
    "    test_df[\"stringified_input\"] = test_df.apply(\n",
    "        lambda row: stringify_input(row, model_name), axis=1\n",
    "    )\n",
    "\n",
    "    all_test_predictions = []\n",
    "\n",
    "    for fold_idx in range(n_fold):\n",
    "        print(f\"Loading fold {fold_idx + 1} model...\")\n",
    "\n",
    "        # Load tokenizer\n",
    "\n",
    "        model_path = os.path.join(model_name, f\"fold_{fold_idx}\")\n",
    "        if use_lora:\n",
    "            model_path = model_name\n",
    "\n",
    "        tokenizer = get_tokenizer(model_path)\n",
    "\n",
    "        # Prepare test dataset\n",
    "        test_ds = Dataset.from_pandas(test_df[[\"stringified_input\"]])\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[\"stringified_input\"])\n",
    "\n",
    "        test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "        # Load model and generate predictions\n",
    "        qlora_config = {\n",
    "            \"torch_dtype\": torch.float16,\n",
    "        }\n",
    "        if \"ettin\" not in model_name.lower():\n",
    "            qlora_config[\"device_map\"] = \"auto\"\n",
    "        seq_model = get_sequence_classifier(model_path, n_classes, qlora_config)\n",
    "\n",
    "        # Handle padding token\n",
    "        if (\n",
    "            \"gemma\" in model_name.lower()\n",
    "            or \"qwen\" in model_name.lower()\n",
    "            or \"deepseek-math\" in model_name.lower()\n",
    "            or \"llama-3.1\" in model_name.lower()\n",
    "            or \"acemath\" in model_name.lower()\n",
    "        ):\n",
    "            if tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            seq_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "        if use_lora:\n",
    "            fold_model_path = os.path.join(adapter_path, f\"fold_{fold_idx}\")\n",
    "            seq_model = PeftModel.from_pretrained(seq_model, fold_model_path)\n",
    "\n",
    "        # Create trainer for inference\n",
    "        training_args = get_training_arguments(\n",
    "            bf16_support=\"/kaggle\" not in ROOT_PATH,\n",
    "        )\n",
    "        trainer = get_trainer(seq_model, tokenizer, training_args, test_ds, test_ds)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = trainer.predict(test_ds)\n",
    "        probs = torch.nn.functional.softmax(\n",
    "            torch.tensor(predictions.predictions), dim=1\n",
    "        ).numpy()\n",
    "\n",
    "        all_test_predictions.append(probs)\n",
    "\n",
    "        # Clean up\n",
    "        del seq_model, tokenizer, training_args, trainer\n",
    "        del test_ds, predictions, probs\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "        clear_memory()\n",
    "\n",
    "    # Ensemble predictions (simple average)\n",
    "    ensemble_predictions = np.mean(all_test_predictions, axis=0)\n",
    "\n",
    "    # Generate submission\n",
    "    topk = np.argsort(-ensemble_predictions, axis=1)[:, :TOP_K]\n",
    "    flat_topk = topk.flatten()\n",
    "    decoded_labels = le.inverse_transform(flat_topk)\n",
    "    topk_labels = decoded_labels.reshape(topk.shape)\n",
    "\n",
    "    joined_preds = [\" \".join(row) for row in topk_labels]\n",
    "\n",
    "    submission = pd.DataFrame(\n",
    "        {\"row_id\": test_df.row_id.values, \"Category:Misconception\": joined_preds}\n",
    "    )\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "\n",
    "    print(f\"Test predictions saved to '{submission_file}'\")\n",
    "    return ensemble_predictions, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_variation in MODEL_VARIATIONS:\n",
    "    test_predictions, submission = generate_test_predictions(\n",
    "        model_variation[\"model_name\"],\n",
    "        model_variation[\"adapter_path\"],\n",
    "        model_variation[\"use_lora\"],\n",
    "        model_variation[\"n_fold\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/code/bibanh/lb-0-944-the-art-of-ensemble#4.-ENSEMBLE-EVERYTHING\n",
    "def get_top_k_ensemble(list_of_predictions, k=3):\n",
    "    predictions = []\n",
    "    weights = []\n",
    "    for i, lp in enumerate(list_of_predictions):\n",
    "        predictions.append(lp.split(\"|\"))\n",
    "        if i in []:\n",
    "            w = 1.2\n",
    "        elif i in []:\n",
    "            w = 1.0\n",
    "        else:\n",
    "            w = 1.0\n",
    "        weights.append(w)\n",
    "    score = defaultdict(int)\n",
    "\n",
    "    for i, lst in enumerate(predictions):\n",
    "        weight = weights[i]\n",
    "        for rank, item in enumerate(lst):\n",
    "            score[item] += (len(lst) - rank) * weight\n",
    "\n",
    "    sorted_items = sorted(score.items(), key=lambda x: -x[1])\n",
    "    return ' '.join([item for item, _ in sorted_items[:k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for model_variation in MODEL_VARIATIONS:\n",
    "    model_name = model_variation[\"submission_file\"].replace(\"submission_\", \"\").replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(model_variation[\"submission_file\"])\n",
    "    dfs[model_name] = df\n",
    "\n",
    "ensemble_df = dfs[model_name][['row_id']].copy()\n",
    "for model_name in dfs:\n",
    "    ensemble_df[f\"predictions_{model_name}\"] = dfs[model_name][\"Category:Misconception\"]\n",
    "\n",
    "print(\"Ensemble df shape:\", ensemble_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df[\"Category:Misconception\"] = ensemble_df.apply(\n",
    "    lambda row: get_top_k_ensemble(\n",
    "        [\n",
    "            row[\n",
    "                f\"predictions_{model_variations['submission_file'].replace('submission_', '').replace('.csv', '')}\"\n",
    "            ]\n",
    "            for model_variations in MODEL_VARIATIONS\n",
    "        ],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "ensemble_df[[\"row_id\", \"Category:Misconception\"]].to_csv(\"submission.csv\", index=False)\n",
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a8c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
