# map-kaggle-competition

### Changes

| Model                     | Architecture | LoRA Config   | Learning Rate | Batch Size | CV Score | LB Score |
| ------------------------- | ------------ | ------------- | ------------- | ---------- | -------- | -------- |
| Qwen3-14B                 | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.945    | 0.943    |
| gemma-2-9b-it             | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.942    | 0.942    |
| DeepSeek-R1-0528-Qwen3-8B | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.945    | 0.942    |
| deepseek-math-7b-instruct | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.943    | 0.942    |
| Qwen3-Embedding-4B        | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.945    | 0.942    |
| AceReason-Nemotron-1.1-7B | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.943    | 0.938    |
| Llama-3.1-8B-Instruct     | QLoRA-4bit   | r=8, alpha=32 | 2e-4          | 16         | 0.943    | 0.939    |
| Ettin-Encoder-1b          | Fine-Tune    | -             | 4e-5          | 32         | 0.944    | 0.941    |

### Ensemble Submission

| Qwen3-14B | DeepSeek-R1-0528-Qwen3-8B | deepseek-math-7b-instruct | gemma-2-9b-it | Qwen3-Embedding-4B | Ettin-Encoder-1b | Top@k | LB Score |
| --------- | ------------------------- | ------------------------- | ------------- | ------------------ | ---------------- | ----- | -------- |
| ✅         | ✅                         | ✅                         | ✅             | ✅                  | ❌                | 3     | 0.946    |
| ✅         | ✅                         | ✅                         | ✅             | ✅                  | ❌                | 10    | 0.946    |
| ✅         | ✅                         | ✅                         | ✅             | ❌                  | ❌                | 3     | 0.944    |
| ✅         | ❌                         | ✅                         | ✅             | ✅                  | ❌                | 3     | 0.945    |
| ✅         | ✅                         | ❌                         | ✅             | ✅                  | ❌                | 3     | 0.945    |
| ✅         | ✅                         | ✅                         | ❌             | ✅                  | ❌                | 3     | 0.945    |
| ✅         | ✅                         | ✅                         | ✅             | ✅                  | ✅                | 10    | 0.947    |
| ✅         | ❌                         | ✅                         | ✅             | ✅                  | ✅                | 10    | 0.947    |
| ✅         | ✅                         | ❌                         | ✅             | ✅                  | ✅                | 10    | 0.946    |
| ✅         | ✅                         | ❌                         | ✅             | ❌                  | ❌                | 10    | 0.944    |
| ✅         | ❌                         | ✅                         | ✅             | ❌                  | ❌                | 10    | 0.945    |
| ✅         | ❌                         | ❌                         | ✅             | ✅                  | ❌                | 10    | 0.946    |
| ✅         | ❌                         | ❌                         | ✅             | ✅                  | ✅                | 10    | 0.945    |
| ❌         | ❌                         | ✅                         | ✅             | ✅                  | ❌                | 10    | 0.946    |
| ❌         | ✅                         | ✅                         | ✅             | ✅                  | ❌                | 10    | 0.945    |
| ❌         | ❌                         | ✅                         | ✅             | ✅                  | ✅                | 10    | 0.947    |

### Ensemble Ratio

| Models | Qwen3-14B | DeepSeek-R1-0528-Qwen3-8B | deepseek-math-7b-instruct | gemma-2-9b-it | Qwen3-Embedding-4B | Ettin-Encoder-1b | LB Score       |
| ------ | --------- | ------------------------- | ------------------------- | ------------- | ------------------ | ---------------- | -------------- |
| Ratios | 1.0       | 0                         | 1.0                       | 1.2           | 0.8                | 0.8              | 0.947          |
| Ratios | 1.2       | 0                         | 1.2                       | 1.0           | 0.8                | 0.8              | 0.947          |
| Ratios | 1.2       | 0                         | 0.8                       | 1.0           | 0.8                | 0.8              | 0.947          |
| Ratios | 1.0       | 0                         | 0.8                       | 1.2           | 0.8                | 0.8              | 0.947          |
| Ratios | 1.2       | 0                         | 1.0                       | 1.2           | 0.8                | 0.8              | 0.947          |
| Ratios | 0.8       | 0                         | 1.0                       | 1.2           | 0.8                | 0.8              | 0.947          |
| Ratios | 1.2       | 0                         | 1.0                       | 1.2           | 1.0                | 0.8              | 0.947          |
| Ratios | 0         | 0                         | 1.0                       | 1.0           | 1.2                | 0.8              | 0.946          |
| Ratios | 0         | 0                         | 1.2                       | 1.2           | 1.0                | 0.8              | 0.946          |
| Ratios | 0         | 0                         | 1.0                       | 1.0           | 1.0                | 1.0              | 0.947 (higher) |

### OOF Training

| Models                    | Architecture | LoRA Config   | NFolds | Learning Rate | Batch Size | CV Score (Single Model Score)                         | LB Score |
| ------------------------- | ------------ | ------------- | ------ | ------------- | ---------- | ----------------------------------------------------- | -------- |
| Ettin-Encoder-1b          | Fine-Tune    | -             | 5      | 4e-5          | 32         | 0.94171, 0.94105, 0.94266, 0.94270, 0.94248 - 0.94212 | 0.942    |
| deepseek-math-7b-instruct | QLoRA-4bit   | r=8, alpha=32 | 5      | 2e-4          | 16         | 0.93978, 0.94309, 0.94427, 0.94475, 0.94289 - 0.94295 | 0.945    |
| DeepSeek-R1-0528-Qwen3-8B | QLoRA-4bit   | r=8, alpha=32 | 5      | 2e-4          | 16         | 0.94371, 0.94179, 0.94734, 0.94470, 0.94382 - 0.94427 | 0.947    |
| gemma-2-9b-it             | QLoRA-4bit   | r=8, alpha=32 | 5      | 2e-4          | 16         | 0.93908, 0.94134, 0.94066, 0.93880, 0.94186 - 0.94035 | 0.942    |
| Qwen3-Embedding-4B        | LoRA         | r=8, alpha=32 | 5      | 2e-4          | 8          | 0.94348, 0.94293, 0.94575, 0.94211, 0.94250 - 0.94335 | 0.947    |
| Qwen3-Embedding-4B        | QLoRA-4bit   | r=8, alpha=32 | 5      | 2e-4          | 16         | 0.94396, 0.94275, 0.94527, 0.94450, 0.94561 - 0.94442 | 0.946    |
| Qwen/Qwen3-1.7B           | Fine-Tune    | -             | 5      | 4e-5          | 16         | 0.93921, 0.93961, 0.94027, 0.94168, 0.94227 - 0.94061 | 0.942    |

### OOF Ensemble Submission

| DeepSeek-R1-0528-Qwen3-8B | deepseek-math-7b-instruct | gemma-2-9b-it | Qwen3-Embedding-4B | Ettin-Encoder-1b | LB Score |
| ------------------------- | ------------------------- | ------------- | ------------------ | ---------------- | -------- |
| ❌                         | ✅                         | ❌             | ❌                  | ✅                | 0.944    |
| ❌                         | ✅                         | ❌             | ✅                  | ✅                | 0.947    |
| ❌                         | ✅ (1.0)                   | ❌             | ✅ (1.2)            | ✅ (0.8)          | 0.948    |
| ✅ (1.0)                   | ❌                         | ❌             | ✅ (1.2)            | ✅ (0.8)          | -        |
| ✅ (1.2)                   | ❌                         | ❌             | ✅ (1.0)            | ✅ (0.8)          | -        |
| ✅ (1.2)                   | ✅ (1.0)                   | ❌             | ❌                  | ✅ (0.8)          | -        |
| ❌                         | ✅                         | ❌             | ✅                  | ❌                | 0.945    |
| ❌                         | ✅                         | ✅             | ❌                  | ❌                | 0.945    |
| ❌                         | ✅                         | ✅             | ✅                  | ❌                | 0.947    |
| ✅                         | ❌                         | ❌             | ✅                  | ❌                | 0.947    |

